{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "# path variables\n",
    "import sys\n",
    "project_path = '/Users/naresh/Downloads/ds_models/onboarding_fraud_model_v2/'\n",
    "sys.path.insert(0, project_path+'config')\n",
    "from config import SQLQuery\n",
    "\n",
    "# core libraries\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textstat\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "import validators\n",
    "import requests\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from model_evaluations import model_metrics, cross_validation\n",
    "from model_building import tune_hyperparameters\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, precision_score, recall_score, roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from fuzzywuzzy import fuzz\n",
    "from itertools import permutations\n",
    "from nltk.util import ngrams\n",
    "from nltk.collocations import BigramAssocMeasures, TrigramAssocMeasures, BigramCollocationFinder, TrigramCollocationFinder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom DS Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from stability_monitoring import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4505, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw data - apps and alloy sources\n",
    "year = '2021_2022'\n",
    "file = 'apps_raw_dataset_2024_oot.pkl'\n",
    "path = project_path + 'data/'\n",
    "df_raw = pd.read_pickle(path + file)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting uppercase column names to lowercase column names\n",
    "cols_lower = []\n",
    "for col in df_raw.columns:\n",
    "    cols_lower.append(col.lower())\n",
    "    df_raw[col.lower()]=df_raw[col]\n",
    "\n",
    "df_raw = df_raw[cols_lower] # selecting only lowercase columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4488\n",
       "1      17\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4488\n",
       "1      17\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating train and test data\n",
    "x_oot = df_raw\n",
    "y_oot = x_oot['target']\n",
    "\n",
    "x_oot['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_oot[['ein_ssn','has_international_business']] = x_oot[['ein_ssn','has_international_business']].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['person_fraud_score', 'person_kyc_score', 'sentilink_abuse_score', 'sentilink_first_party_synthetic_score'\n",
    "            ,'sentilink_third_party_synthetic_score', 'sentilink_id_theft_score', 'socure_sigma', 'socure_emailrisk', 'socure_phonerisk'\n",
    "            ,'socure_addressrisk','number_of_employees']\n",
    "num_features2 = ['business_address_zip', 'phone']\n",
    "bool_features = ['ein_ssn','has_international_business']\n",
    "cat_features = ['iovation_device_type', 'estimated_monthly_revenue', 'incoming_ach_payments', 'check_deposit_amount'\n",
    "               , 'incoming_wire_transfer', 'outgoing_ach_and_checks', 'outgoing_wire_transfers', 'line_type', 'industry_category_name']\n",
    "list_features = ['person_fraud_tags', 'person_kyc_tags', 'socure_reason_code', 'socure_kyc_field_validations'\n",
    "                ,'socure_kyc_reason_code', 'socure_emailrisk_reason_code', 'socure_phonerisk_reason_code'\n",
    "                ,'socure_addressrisk_reason_code', 'purpose_of_account', 'touch_point_emails', 'owner_list']\n",
    "high_cardinality_features = ['iovation_device_timezone', 'iovation_device_ip', 'iovation_device_ip_isp', 'iovation_device_ip_org' \n",
    "                            ,'iovation_device_ip_city', 'iovation_device_ip_region', 'carrier', 'email', 'email_domain', 'industry_name'\n",
    "                            , 'website', 'business_address_city', 'business_address_state', 'industry_category_from_pitch'\n",
    "                            , 'company_name']\n",
    "text_features = ['business_pitch']\n",
    "id_features = ['application_id', 'business_id', 'target', 'expensed_fraud_loss', 'fraud_score', 'deposit_score']\n",
    "datetime_features = ['application_start_datetime', 'application_complete_datetime', 'application_resubmitted_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4505, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_features = num_features + num_features2 + bool_features + cat_features + list_features + high_cardinality_features + text_features + id_features + datetime_features\n",
    "x_oot = x_oot[raw_features]\n",
    "x_oot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # convert all string features to lowercase\n",
    "# string_features = cat_features + list_features + high_cardinality_features + text_features\n",
    "\n",
    "# for col in string_features:\n",
    "#     print(col)\n",
    "#     x_train[col] = x_train[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all type of nulls to one null format\n",
    "def convert_nulls_to_one_format(df:pd.DataFrame):\n",
    "    for col in df.columns:\n",
    "        idx = df.index[df[col].isnull()].tolist()\n",
    "        idx.extend(df.index[df[col].isna()].tolist())\n",
    "        idx.extend(df.index[df[col] == ''].tolist())\n",
    "        idx.extend(df.index[df[col] == '[]'].tolist())\n",
    "        idx = list(set(idx))\n",
    "        df.loc[idx, col] = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Saving the imputing values of each feature\n",
    "\n",
    "# # Numerical\n",
    "# df_impute_numerical = df[num_features].median()\n",
    "# df_impute_numerical = pd.DataFrame(df_impute_numerical, columns=['impute_value']).reset_index().rename(columns={'index':'feature'})\n",
    "\n",
    "\n",
    "# data_impute_list = []\n",
    "# for col in cat_features+high_cardinality_features+list_features+bool_features:\n",
    "#     if col not in ['email','touch_point_emails','owner_list','website','company_name']:\n",
    "#         mode_val = df[col].mode()\n",
    "#         if len(mode_val)==1:\n",
    "#             data_impute_list.append([col, mode_val[0]])\n",
    "#         else:\n",
    "#             data_impute_list.append([col, mode_val[0]])\n",
    "# # Categorical\n",
    "# df_impute_categorical = pd.DataFrame(data_impute_list, columns=['impute_value', 'feature'])\n",
    "\n",
    "# df_impute_custom = pd.DataFrame([['email','na'], ['touch_point_emails','na'], ['owner_list','na'], ['website','na'],\n",
    "#                                 ['company_name','na']], columns=['feature','impute_value'])\n",
    "# # Combining all imputes\n",
    "# df_impute = pd.concat([df_impute_numerical,df_impute_categorical, df_impute_custom], axis=0)\n",
    "# df_impute.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# df_impute.to_pickle(project_path+'models/df_impute.pkl') # Save the impute values as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load impute df\n",
    "df_impute = pd.read_pickle(project_path+'models/df_impute_'+year+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute all the nulls\n",
    "def fill_null_values(df_impute:pd.DataFrame, data_df:pd.DataFrame,):\n",
    "    df_dict = dict(df_impute.values)\n",
    "    impute_cols = df_impute['feature'].to_list()\n",
    "    for col in data_df.columns.to_list():\n",
    "        if col in impute_cols:\n",
    "            data_df[col] = data_df[col].fillna(df_dict[col])\n",
    "            impute_cols.remove(col)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert all nulls to one format\n",
    "df = convert_nulls_to_one_format(df=df)\n",
    "# Data imputing\n",
    "df = fill_null_values(df_impute, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Features Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ein_ssn'] = df['ein_ssn']*1\n",
    "df['ein_ssn'] = df['ein_ssn'].astype(int)\n",
    "df['has_international_business'] = df['has_international_business']*1\n",
    "df['has_international_business'] = df['has_international_business'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Fetaures Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling nulls with the start date because the difference between start date and complete date remains less than 24 hours\n",
    "df['application_complete_datetime'] = np.where(df['application_complete_datetime'].isnull(), df['application_start_datetime'], \n",
    "                                               df['application_complete_datetime'])\n",
    "df['application_start_datetime'] = pd.to_datetime(df['application_start_datetime'])\n",
    "df['application_complete_datetime'] = pd.to_datetime(df['application_complete_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert day of month to the week of month\n",
    "def weekofmonth(val):\n",
    "    if val<=7:\n",
    "        return 1\n",
    "    elif val<=14:\n",
    "        return 2\n",
    "    elif val<=21:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "# Correcting the features values to standard format\n",
    "replace_weekdaytonumber = {'sunday':0, 'monday':1, 'tuesday':2 , 'wednesday':3, 'thursday':4, 'friday':5, 'saturday':6}\n",
    "\n",
    "# App start date features\n",
    "# df['app_start_monthofyear'] = df['application_start_datetime'].dt.month\n",
    "df['app_start_dateofmonth'] = df['application_start_datetime'].dt.day\n",
    "df['app_start_weekofmonth'] = df['app_start_dateofmonth'].apply(weekofmonth)\n",
    "df['app_start_dayofweek'] = df['application_start_datetime'].dt.day_name()\n",
    "# df['app_start_dayofweek'] = df['app_start_dayofweek'].astype('string').apply(weekdaytonumber)\n",
    "df['app_start_dayofweek'] = df['app_start_dayofweek'].replace(replace_weekdaytonumber)\n",
    "df['app_start_hourofday'] = df['application_start_datetime'].dt.hour\n",
    "\n",
    "# App complete date features\n",
    "# df['app_complete_monthofyear'] = df['application_complete_datetime'].dt.month\n",
    "df['app_complete_dateofmonth'] = df['application_complete_datetime'].dt.day\n",
    "df['app_complete_weekofmonth'] = df['app_complete_dateofmonth'].apply(weekofmonth)\n",
    "df['app_complete_dayofweek'] = df['application_complete_datetime'].dt.day_name()\n",
    "# df['app_complete_dayofweek'] = df['app_complete_dayofweek'].astype('string').apply(weekdaytonumber)\n",
    "df['app_complete_dayofweek'] = df['app_complete_dayofweek'].replace(replace_weekdaytonumber)\n",
    "df['app_complete_hourofday'] = df['application_complete_datetime'].dt.hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = 'iovation_device_type'\n",
    "df[col] = df[col].str.lower()\n",
    "df[col] = np.where(df[col].isin(['iphone', 'mac','ipad', 'ipod']), 'apple', df[col])\n",
    "df[col] = np.where(df[col].isin(['chromeos', 'linux', 'handheld_other']), 'other', df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_features = ['estimated_monthly_revenue','incoming_ach_payments','check_deposit_amount','incoming_wire_transfer',\n",
    "                      'outgoing_ach_and_checks','outgoing_wire_transfers']\n",
    "\n",
    "# Correcting the features values to standard format\n",
    "estimated_features_replace_values1 = {'$0':'0k', \n",
    "                                      '$0 - $1k':'1k', '<$1k':'1k', '$1 - $1k':'1k', \n",
    "                                      '$1k - $5k':'1k_plus', '$1k +':'1k_plus', \n",
    "                                      '$5k - $20k':'5k_plus', '$5k +':'5k_plus', '$20k - $50k':'5k_plus', \n",
    "                                      '$50k +':'50k_plus' }\n",
    "for col in estimated_features:\n",
    "    df[col] = df[col].str.lower()\n",
    "df[estimated_features] = df[estimated_features].replace(estimated_features_replace_values1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_features_interaction = []\n",
    "for value in ['0k','1k','1k_plus','5k_plus','50k_plus']:\n",
    "    estimated_features_interaction.append('estimated_features_'+value+'_count')\n",
    "    df['estimated_features_'+value+'_count'] = df[estimated_features][df[estimated_features]==value].count(axis=1)\n",
    "\n",
    "df['estimated_features_same_value_flag'] = df[df[estimated_features_interaction]==6].any(axis=1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_features_outgoing = ['outgoing_ach_and_checks', 'outgoing_wire_transfers']\n",
    "estimated_features_incoming = list(set(estimated_features)-set(estimated_features_outgoing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace the ordinal values into numerical ordinal values\n",
    "estimated_features_replace_values2 = {'0k':0, '1k':500, '1k_plus':1000, '5k_plus':5000, '50k_plus':50000}\n",
    "df[estimated_features] = df[estimated_features].replace(estimated_features_replace_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deriving estimated interaction features\n",
    "df['total_incoming_vol'] = df[estimated_features_incoming].sum(axis=1)\n",
    "df['total_outgoing_vol'] = df[estimated_features_outgoing].sum(axis=1)\n",
    "df['total_txns_vol'] = df['total_incoming_vol'] + df['total_outgoing_vol']\n",
    "df['cashflow'] = df['total_incoming_vol'] - df['total_outgoing_vol']\n",
    "\n",
    "df['ach_mrdc_incoming_vol'] = df[['incoming_ach_payments','check_deposit_amount']].sum(axis=1) \n",
    "df['ach_mrdc_outgoing_vol'] = df['outgoing_ach_and_checks']\n",
    "df['ach_mrdc_total_txns_vol'] = df['ach_mrdc_incoming_vol'] + df['ach_mrdc_outgoing_vol']\n",
    "df['ach_mrdc_cashflow'] = df['ach_mrdc_incoming_vol'] - df['ach_mrdc_outgoing_vol']\n",
    "\n",
    "df['wire_incoming_vol'] = df['incoming_wire_transfer']\n",
    "df['wire_outgoing_vol'] = df['outgoing_wire_transfers']\n",
    "df['wire_total_txns_vol'] = df['wire_incoming_vol'] + df['wire_outgoing_vol']\n",
    "df['wire_cashflow'] = df['wire_incoming_vol'] - df['wire_outgoing_vol']\n",
    "\n",
    "\n",
    "# Ratio's\n",
    "replace_dict = {np.nan:0, np.inf:0, -np.inf:0}\n",
    "df['outgoing_to_incoming_ratio'] = df['total_outgoing_vol'].div(df['total_incoming_vol']).replace(replace_dict)\n",
    "df['cashflow_to_total_txns_vol_ratio'] = df['cashflow'].div(df['total_txns_vol']).replace(replace_dict)\n",
    "df['wire_outgoing_to_incoming_ratio'] = df['outgoing_wire_transfers'].div(df['total_incoming_vol']).replace(replace_dict)\n",
    "df['ach_mrdc_outgoing_to_incoming_ratio'] = df['outgoing_ach_and_checks'].div(df[['incoming_ach_payments','check_deposit_amount'\n",
    "                                                                                 ]].sum(axis=1)).replace(replace_dict)\n",
    "df['incoming_ach_to_revenue_ratio'] = df['incoming_ach_payments'].div(df['estimated_monthly_revenue']).replace(replace_dict)\n",
    "df['incoming_ach_mrdc_to_revenue_ratio'] = df[['incoming_ach_payments','check_deposit_amount']].sum(axis=1).div(df['estimated_monthly_revenue']).replace(replace_dict)\n",
    "\n",
    "df['ach_mrdc_total_txns_vol_to_total_txns_vol_ratio'] = (df['ach_mrdc_incoming_vol']+ df['ach_mrdc_outgoing_vol'])/df['total_txns_vol']\n",
    "df['ach_mrdc_incoming_to_total_incoming_vol_ratio'] = df['ach_mrdc_incoming_vol']/df['total_incoming_vol']\n",
    "df['ach_mrdc_outgoing_to_total_outgoing_vol_ratio'] = df['ach_mrdc_outgoing_vol']/df['total_outgoing_vol']\n",
    "\n",
    "df['wire_total_txns_vol_to_total_txns_vol_ratio'] = (df['wire_incoming_vol']+ df['wire_outgoing_vol'])/df['total_txns_vol']\n",
    "df['wire_incoming_to_total_incoming_vol_ratio'] = df['wire_incoming_vol']/df['total_incoming_vol']\n",
    "df['wire_outgoing_to_total_outgoing_vol_ratio'] = df['wire_outgoing_vol']/df['total_outgoing_vol']\n",
    "\n",
    "# Ratios of number of employees\n",
    "df['total_incoming_vol_to_employees_ratio'] = df['total_incoming_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['total_outgoing_vol_to_employees_ratio'] = df['total_outgoing_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['total_txns_vol_to_employees_ratio'] = df['total_txns_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['cashflow_to_employees_ratio'] = df['cashflow'].div(df['number_of_employees']).replace(replace_dict)\n",
    "\n",
    "df['wire_incoming_vol_to_employees_ratio'] = df['wire_incoming_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['wire_outgoing_vol_to_employees_ratio'] = df['wire_outgoing_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['wire_total_txns_vol_to_employees_ratio'] = df['wire_total_txns_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['wire_cashflow_to_employees_ratio'] = df['wire_cashflow'].div(df['number_of_employees']).replace(replace_dict)\n",
    "\n",
    "df['ach_mrdc_incoming_vol_to_employees_ratio'] = df['ach_mrdc_incoming_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['ach_mrdc_outgoing_vol_to_employees_ratio'] = df['ach_mrdc_outgoing_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['ach_mrdc_total_txns_vol_to_employees_ratio'] = df['ach_mrdc_total_txns_vol'].div(df['number_of_employees']).replace(replace_dict)\n",
    "df['ach_mrdc_cashflow_to_employees_ratio'] = df['ach_mrdc_cashflow'].div(df['number_of_employees']).replace(replace_dict)\n",
    "\n",
    "df['estimated_monthly_revenue_to_employees_ratio'] = df['estimated_monthly_revenue'].div(df['number_of_employees']).replace(replace_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot = 0\n",
    "# tot_fraud = 0\n",
    "# for col in estimated_features_interaction:\n",
    "#     print(col, ':',df[df[col]==6].shape[0], df[df[col]==6].target.mean())\n",
    "#     tot = tot+df[df[col]==6].shape[0]\n",
    "#     tot_fraud = tot_fraud + df[df[col]==6].target.sum()\n",
    "# tot, tot_fraud, tot_fraud/tot, tot/df.shape[0], df.target.sum(), (df.target.sum()-tot_fraud)/(df.shape[0]-tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grouping the features values to the observed variance\n",
    "def estimated_feature_engg(value):\n",
    "    if value == None:\n",
    "        return None\n",
    "    value = value.lower()\n",
    "    if value in ['$0', '$0 - $1k', '<$1k']:\n",
    "        # return 'upto_1k'\n",
    "        return 0\n",
    "    elif value in ['$1k +', '$5k +', '$50k +']:\n",
    "        # return '1k_plus'\n",
    "        return 1\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Grouping the features values to the observed variance\n",
    "def estimated_feature_engg(value):\n",
    "    if value == None:\n",
    "        return None\n",
    "    if value<=500:\n",
    "        return 0\n",
    "    elif value>=1000:\n",
    "        return 1\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "for col in estimated_features:\n",
    "    df[col] = df[col].apply(estimated_feature_engg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'industry_category_name'\n",
    "df[col] = df[col].str.lower()\n",
    "df[col] = np.where(df[col].isin(['utilities','mining', 'agriculture, forestry, fishing and hunting', 'wholesale trade', \n",
    "                                 'accommodation and food services', 'administrative and support and waste management and remediation services',\n",
    "                                 'construction', 'finance and insurance', 'mining', 'other services', 'health care and social assistance',\n",
    "                                'manufacturing', 'public administration']), 'cat1', 'cat2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Cardinality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'iovation_device_timezone'\n",
    "df[col] = df[col].astype('float64')\n",
    "df[col] = np.where(df[col].isin([300,360,480]), df[col], 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'email_domain'\n",
    "l1 = ['gmail.com']\n",
    "l2 = ['yahoo.com','outlook.com','icloud.com','hotmail.com','aol.com','protonmail.com']\n",
    "df[col] = np.where(df[col].isin(l1), 'l1', np.where(df[col].isin(l2), 'l2', 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'iovation_device_ip_isp'\n",
    "df[col] = df[col].str.lower()\n",
    "df[col] = np.where(df[col].str.contains('t-mobile*'),'tmobile',df[col])\n",
    "df[col] = np.where(df[col].str.contains('verizon'),'verizon',df[col])\n",
    "df[col] = np.where(df[col].str.contains('at&t'),'att',df[col])\n",
    "df[col] = np.where(df[col].str.match('att'),'att',df[col])\n",
    "df[col] = np.where(df[col].str.match('charter [b|c]'),'charter',df[col])\n",
    "df[col] = np.where(df[col].str.match('comcast'),'comcast',df[col])\n",
    "df[col] = np.where(df[col].isin(['tmobile','att','charter','verizon','comcast']),df[col],'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'iovation_device_ip_org'\n",
    "df[col] = df[col].str.lower()\n",
    "df[col] = np.where(df[col].str.contains('t-mobile*'),'tmobile',df[col])\n",
    "df[col] = np.where(df[col].str.contains('verizon'),'verizon',df[col])\n",
    "df[col] = np.where(df[col].str.contains('at&t'),'att',df[col])\n",
    "df[col] = np.where(df[col].str.match('att'),'att',df[col])\n",
    "df[col] = np.where(df[col].str.match('charter [b|c]'),'charter',df[col])\n",
    "df[col] = np.where(df[col].str.match('comcast'),'comcast',df[col])\n",
    "df[col] = np.where(df[col].isin(['tmobile','att','charter','verizon','comcast']),df[col],'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'carrier'\n",
    "df[col] = df[col].str.lower()\n",
    "df[col] = np.where(df[col].str.contains('t-mobile*'),'tmobile',df[col])\n",
    "df[col] = np.where(df[col].str.contains('verizon'),'verizon',df[col])\n",
    "df[col] = np.where(df[col].str.contains('at&t'),'att',df[col])\n",
    "df[col] = np.where(df[col].str.match('att'),'att',df[col])\n",
    "df[col] = np.where(df[col].isin(['tmobile','att','verizon']),df[col],'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iovation_device_timezone',\n",
       " 'iovation_device_ip',\n",
       " 'iovation_device_ip_isp',\n",
       " 'iovation_device_ip_org',\n",
       " 'iovation_device_ip_city',\n",
       " 'iovation_device_ip_region',\n",
       " 'carrier',\n",
       " 'email',\n",
       " 'email_domain',\n",
       " 'industry_name',\n",
       " 'website',\n",
       " 'business_address_city',\n",
       " 'business_address_state',\n",
       " 'industry_category_from_pitch',\n",
       " 'company_name']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cardinality_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_address_class(val:str):\n",
    "    if val==None or val=='':\n",
    "        return None\n",
    "    else:\n",
    "        if len(val)<=15:\n",
    "            val_split = val.split('.')\n",
    "            if 0<=int(val_split[0])<=127:\n",
    "                class_val = 'a'\n",
    "            elif 128<=int(val_split[0])<=191:\n",
    "                class_val = 'b'\n",
    "            elif 192<=int(val_split[0])<=223:\n",
    "                class_val = 'c'\n",
    "            elif 224<=int(val_split[0])<=239:\n",
    "                class_val = 'd'\n",
    "            elif 240<=int(val_split[0])<=255:\n",
    "                class_val = 'e'\n",
    "            else:\n",
    "                class_val = 'na'\n",
    "            return class_val\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "col = 'iovation_device_ip'\n",
    "df['ip_class'] = df[col].apply(ip_address_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "business_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_readability_features(text):\n",
    "    if text==None or text=='':\n",
    "        return_features = {'flesch_reading_ease': 0, 'smog_index': 0, 'flesch_kincaid_grade': 0, 'coleman_liau_index': 0, \n",
    "                           'automated_readability_index': 0, 'dale_chall_readability_score': 0, 'difficult_words': 0,\n",
    "                           'linsear_write_formula': 0, 'gunning_fog': 0, 'text_standard': '-1th and 0th grade'}\n",
    "        return_features = tuple(return_val.values())\n",
    "    \n",
    "    else:\n",
    "        return_features = {\n",
    "            'flesch_reading_ease': textstat.flesch_reading_ease(text),\n",
    "            'smog_index': textstat.smog_index(text),\n",
    "            'flesch_kincaid_grade': textstat.flesch_kincaid_grade(text),\n",
    "            'coleman_liau_index': textstat.coleman_liau_index(text),\n",
    "            'automated_readability_index': textstat.automated_readability_index(text),\n",
    "            'dale_chall_readability_score': textstat.dale_chall_readability_score(text),\n",
    "            'difficult_words': textstat.difficult_words(text),\n",
    "            'linsear_write_formula': textstat.linsear_write_formula(text),\n",
    "            'gunning_fog': textstat.gunning_fog(text),\n",
    "            'text_standard': textstat.text_standard(text)\n",
    "        }\n",
    "        return_features = tuple(return_features.values())\n",
    "        \n",
    "    return return_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4505, 112)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = 'business_pitch'\n",
    "readability_columns = ['flesch_reading_ease', 'smog_index', 'flesch_kincaid_grade', 'coleman_liau_index', 'automated_readability_index',\n",
    "                       'dale_chall_readability_score', 'difficult_words', 'linsear_write_formula', 'gunning_fog', 'text_standard']\n",
    "df[readability_columns] = pd.DataFrame(df[col].apply(extract_readability_features).tolist(),index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# engg text_standard feature\n",
    "# text_standard_vals = list(set(df['text_standard'].values))\n",
    "# text_standard_vals.sort()\n",
    "# text_standard_vals_replace = [0, -1, 1, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 3, 31, 32, 326, \n",
    "#                               33, 34, 35, 36, 37, 39, 4, 41, 43, 5, 54, 6, 68, 7, 8, 9, 10]\n",
    "# text_standard_vals_replace = [x + 1 for x in text_standard_vals_replace]\n",
    "# df['text_standard_ordinals'] = df['text_standard'].replace(text_standard_vals, text_standard_vals_replace)\n",
    "\n",
    "# text_standard feature grouping\n",
    "df['text_standard_levels'] = np.where(df['text_standard'].isin(['6th and 7th grade','7th and 8th grade','8th and 9th grade', '9th and 10th grade']\n",
    "                                               ), 'l2', (np.where(df['text_standard'].isin(['-1th and 0th grade','0th and 1st grade','1st and 2nd grade','2nd and 3rd grade','3rd and 4th grade',\n",
    "                                                                                            '4th and 5th grade','5th and 6th grade']), 'l1', 'l3'))\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linguistic features\n",
    "def extract_linguistic_features(text):\n",
    "   \n",
    "    if text==None or text=='':\n",
    "        return (0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)\n",
    "    else:\n",
    "        # print(text,'\\n\\n')\n",
    "        words = nltk.word_tokenize(text)\n",
    "        total_tokens = len(words)\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        syllable_count = sum(textstat.syllable_count(word) for word in words)\n",
    "        polysyllable_count = len([word for word in words if textstat.syllable_count(word) >= 3])\n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "        pos_counts = Counter(tag for word, tag in pos_tags)\n",
    "\n",
    "        # POS Tag Ratios\n",
    "        pos_ratios = {tag: count / total_tokens for tag, count in pos_counts.items()}\n",
    "        pos_ratios = dict(zip(['pos_ratio_'+key for key in pos_ratios.keys()], pos_ratios.values())) # adding prefix to the keys\n",
    "\n",
    "        # # POS Tag Sequences\n",
    "        # pos_sequence = ' '.join(tag for word, tag in pos_tags)\n",
    "        # words_pos = nltk.word_tokenize(pos_sequence)\n",
    "\n",
    "        # # POS Tag N-grams\n",
    "        # bigrams = list(ngrams([tag for word, tag in pos_tags], 2))\n",
    "        # trigrams = list(ngrams([tag for word, tag in pos_tags], 3))\n",
    "        # # Count bigrams and trigrams\n",
    "        # bigram_counts = Counter(bigrams)\n",
    "        # trigram_counts = Counter(trigrams)\n",
    "\n",
    "        # # Find important bigrams using mutual information\n",
    "        # bigram_measures = BigramAssocMeasures()\n",
    "        # bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "        # important_bigrams = bigram_finder.nbest(bigram_measures.pmi, 3)\n",
    "        \n",
    "        # # Find important trigrams using mutual information\n",
    "        # trigram_measures = TrigramAssocMeasures()\n",
    "        # trigram_finder = TrigramCollocationFinder.from_words(words)\n",
    "        # important_trigrams = trigram_finder.nbest(trigram_measures.pmi, 3)\n",
    "\n",
    "        # POS Diversity\n",
    "        pos_diversity = len(pos_counts) / total_tokens\n",
    "\n",
    "        # Custom POS Tag Features (e.g., Noun to Verb Ratio)\n",
    "        noun_count = sum(count for tag, count in pos_counts.items() if tag.startswith('NN'))\n",
    "        verb_count = sum(count for tag, count in pos_counts.items() if tag.startswith('VB'))\n",
    "        noun_verb_ratio = noun_count / (verb_count + 1)\n",
    "        \n",
    "        blob = TextBlob(text)\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        vader_sentiment = analyzer.polarity_scores(text)\n",
    "\n",
    "        pos_counts = dict(zip(['pos_count_'+key for key in pos_counts.keys()], pos_counts.values())) # adding prefix to the keys\n",
    "        linguistic_features = {\n",
    "            'total_word_count': total_tokens,\n",
    "            'sentence_count': len(sentences),\n",
    "            'average_sentence_length': total_tokens / len(sentences),\n",
    "            'average_word_length': sum(len(word) for word in words) / total_tokens,\n",
    "            'syllable_count': syllable_count,\n",
    "            'polysyllable_count': polysyllable_count,\n",
    "            'unique_words_count': len(set(words)),\n",
    "            'type_token_ratio': len(set(words)) / total_tokens,\n",
    "            'lexical_density': sum(1 for tag in pos_tags if tag[1] in ['NN', 'VB', 'JJ', 'RB']) / total_tokens,\n",
    "            'pos_counts': pos_counts,\n",
    "            'textblob_polarity': blob.sentiment.polarity, \n",
    "            'textblob_subjectivity': blob.sentiment.subjectivity,\n",
    "            'vader_neg': vader_sentiment['neg'],\n",
    "            'vader_neu': vader_sentiment['neu'],\n",
    "            'vader_pos': vader_sentiment['pos'],\n",
    "            'vader_compound': vader_sentiment['compound'],\n",
    "            'pos_diversity': pos_diversity,\n",
    "            'noun_to_verb_ratio': noun_verb_ratio,\n",
    "            'pos_ratios':pos_ratios\n",
    "\n",
    "        }\n",
    "        linguistic_features = tuple(linguistic_features.values())\n",
    "        \n",
    "        return linguistic_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = 'business_pitch'\n",
    "linguistic_columns = ['total_word_count','sentence_count','average_sentence_length','average_word_length','syllable_count',\n",
    "                      'polysyllable_count','unique_words_count','type_token_ratio','lexical_density','pos_counts','textblob_polarity',\n",
    "                      'textblob_subjectivity','vader_neg','vader_neu','vader_pos','vader_compound','pos_diversity','noun_to_verb_ratio',\n",
    "                      'pos_ratios']\n",
    "df[linguistic_columns] = pd.DataFrame(df[col].apply(extract_linguistic_features).tolist(),index=df.index)\n",
    "\n",
    "# exploding POS tags count features and creating important columns\n",
    "pos_tags_count_features = ['pos_count_NN','pos_count_NNS','pos_count_NNP','pos_count_NNPS','pos_count_VB','pos_count_VBP','pos_count_VBG', \n",
    "                           'pos_count_VBN','pos_count_VBZ','pos_count_VBD','pos_count_CC','pos_count_PRP','pos_count_JJ','pos_count_TO',\n",
    "                           'pos_count_IN','pos_count_RB']\n",
    "df = pd.concat([df,pd.json_normalize(df['pos_counts'])[pos_tags_count_features].fillna(0)], axis=1)\n",
    "\n",
    "# exploding POS tags ratio features and creating important columns\n",
    "pos_tags_ratio_features = ['pos_ratio_NN','pos_ratio_NNS','pos_ratio_NNP','pos_ratio_NNPS','pos_ratio_VB','pos_ratio_VBP','pos_ratio_VBG', \n",
    "                           'pos_ratio_VBN','pos_ratio_VBZ','pos_ratio_VBD','pos_ratio_CC','pos_ratio_PRP','pos_ratio_JJ','pos_ratio_TO', \n",
    "                           'pos_ratio_IN','pos_ratio_RB']\n",
    "df = pd.concat([df,pd.json_normalize(df['pos_ratios'])[pos_tags_ratio_features].fillna(0)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linguistic_columns2 = list(set(linguistic_columns)-set(['pos_counts','pos_ratios']))\n",
    "df[linguistic_columns2] = df[linguistic_columns2].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Values Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "socure_cols = ['socure_phonerisk_reason_code','socure_addressrisk_reason_code','socure_emailrisk_reason_code'\n",
    "              ,'socure_reason_code', 'socure_kyc_reason_code']\n",
    "df_socure = df[['application_id'] + socure_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the list of reason codes\n",
    "def clean_socure_strings(x):\n",
    "    if x != None:\n",
    "        x = [val.strip(\"\"\"'|[| |\"|,|]\"\"\") for val in x.split('\\n') if not val.strip(\"\"\"'|[| |\"|,|]\"\"\") in ['',None]]\n",
    "    return x\n",
    "\n",
    "socure_cols = ['socure_phonerisk_reason_code','socure_addressrisk_reason_code','socure_emailrisk_reason_code','socure_reason_code','socure_kyc_reason_code']\n",
    "df_socure = df[['application_id','target'] + socure_cols]\n",
    "\n",
    "# Collecting the cleaned reason codes\n",
    "for col in socure_cols:\n",
    "    df_socure[col] = df_socure[col].str.lower()\n",
    "    df_socure[col] = df_socure[col].apply(clean_socure_strings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "socure_cols = ['socure_phonerisk_reason_code','socure_addressrisk_reason_code','socure_emailrisk_reason_code','socure_reason_code','socure_kyc_reason_code']\n",
    "\n",
    "dict_cols = {}\n",
    "for col in socure_cols:\n",
    "    df_socure = df_socure.drop(col, 1).join(df_socure[col].str.join('|').str.get_dummies())\n",
    "    socure_cols = df_socure.columns[df_socure.columns.str.startswith('socure')].to_list()\n",
    "    true_cols = list(set(df_socure.columns.to_list()) - set(socure_cols) - set(['application_id','target']))\n",
    "    new_cols = []\n",
    "    for col2 in true_cols:\n",
    "        new_cols.append(col+'_'+col2)\n",
    "    dict_cols = dict(zip(true_cols, new_cols)) | dict_cols\n",
    "    df_socure.rename(columns=dict_cols, inplace=True)\n",
    "\n",
    "df_socure = df_socure.T\n",
    "df_socure = df_socure[~df_socure.index.duplicated(keep='first')].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "socure_phone_cols = df_socure.columns[df_socure.columns.str.startswith('socure_phone')].to_list()\n",
    "socure_address_cols = df_socure.columns[df_socure.columns.str.startswith('socure_address')].to_list()\n",
    "socure_email_cols = df_socure.columns[df_socure.columns.str.startswith('socure_email')].to_list()\n",
    "socure_reason_cols = df_socure.columns[df_socure.columns.str.startswith('socure_reason')].to_list()\n",
    "socure_kyc_cols = df_socure.columns[df_socure.columns.str.startswith('socure_kyc')].to_list()\n",
    "\n",
    "df_socure['socure_phonerisk_code_count'] = df_socure[socure_phone_cols].sum(axis=1)\n",
    "df_socure['socure_addressrisk_code_count'] = df_socure[socure_address_cols].sum(axis=1)\n",
    "df_socure['socure_emailrisk_code_count'] = df_socure[socure_email_cols].sum(axis=1)\n",
    "df_socure['socure_reason_code_count'] = df_socure[socure_reason_cols].sum(axis=1)\n",
    "df_socure['socure_kyc_code_count'] = df_socure[socure_kyc_cols].sum(axis=1)\n",
    "df_socure['socure_all_codes_count'] = df_socure[socure_phone_cols+socure_address_cols+socure_email_cols+socure_reason_cols+socure_kyc_cols].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading only the trained columns and adding to the test data\n",
    "socure_cols_derived = pd.read_pickle(project_path+'models/socure_reason_codes_columns_'+year+'.pkl')\n",
    "df_tmp = pd.DataFrame(index=range(df.shape[0]),columns=socure_cols_derived['feature'].to_list())\n",
    "df_tmp = df_tmp.fillna(0)\n",
    "\n",
    "df_tmp.update(df_socure)\n",
    "df_tmp = df_tmp.astype('int')\n",
    "df = pd.concat([df,df_tmp], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "socure_kyc_field_validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def socure_kyc_field_extraction(val):\n",
    "    if val==None or val==[] or val=={} or val=='':\n",
    "        return (None, None, None, None, None, None, None, None, None)\n",
    "    else:\n",
    "        val = json.loads(val.lower())\n",
    "        city = val['city']\n",
    "        dob = val['dob']\n",
    "        firstname = val['firstname']\n",
    "        mobilenumber = val['mobilenumber']\n",
    "        ssn = val['ssn']\n",
    "        state = val['state']\n",
    "        streetaddress = val['streetaddress']\n",
    "        surname = val['surname']\n",
    "        zip_val = val['zip']\n",
    "\n",
    "        return (surname, firstname, dob, mobilenumber, ssn, state, city, streetaddress, zip_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "socure_kyc_fields_cols = ['socure_kyc_surname_score', 'socure_kyc_firstname_score', 'socure_kyc_dob_score', 'socure_kyc_mobilenumber_score', \n",
    "                         'socure_kyc_ssn_score', 'socure_kyc_state_score', 'socure_kyc_city_score', 'socure_kyc_streetaddress_score', 'socure_kyc_zip_score']\n",
    "df[socure_kyc_fields_cols] = pd.DataFrame(df.socure_kyc_field_validations.apply(socure_kyc_field_extraction).tolist(),index=df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "purpose_of_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'purpose_of_account'\n",
    "\n",
    "# There are 5 unique purpose of accounts categories\n",
    "unique_vals = ['payroll','accounting','operating','travel expenses','business expenses']\n",
    "# Creating dummies for each unique string\n",
    "purpose_of_accounts_derived_cols = []\n",
    "for val in unique_vals:\n",
    "    new_col = 'purpose_'+val.replace(\" \", \"_\")\n",
    "    purpose_of_accounts_derived_cols.append(new_col)\n",
    "    df[new_col] = 0\n",
    "    idx = df.index[df[col].str.contains(val)==True].tolist()\n",
    "    df.loc[idx, new_col] = 1\n",
    "\n",
    "df['purpose_of_account_count'] = df[purpose_of_accounts_derived_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_cols = ['payroll','accounting','operating','travel_expenses','business_expenses']\n",
    "# for i in unique_cols:\n",
    "#     print(df.groupby(['purpose_'+i])['target'].agg(['sum', 'mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "person_fraud_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'person_fraud_tags'\n",
    "df[col] = df[col].str.lower()\n",
    "df[col+'_flag'] = np.where(df[col].str.contains('not')==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "person_kyc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'person_kyc_tags'\n",
    "df[col] = df[col].str.lower()\n",
    "df[col+'_flag'] = np.where(df[col].str.contains('not')==True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "owner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleaning the list of string and extracting owner name\n",
    "def clean_owner_list_strings(x):\n",
    "    if x == None:\n",
    "        return ''\n",
    "    x = x.strip(\"\"\"'|[| |\"|,|]\"\"\")\n",
    "    if x != '' :\n",
    "        try:\n",
    "            x = [val.strip(\"\"\"'|[| |\"|,|]\"\"\") for val in x.split('\\n') if not val.strip(\"\"\"'|[| |\"|,|]\"\"\") in ['',None,[]]]\n",
    "            x = ''.join(x[0].split(',')[:-3])\n",
    "            x = re.sub(r'\\s+', ' ', x)\n",
    "        except:\n",
    "            return x\n",
    "    return x\n",
    "\n",
    "df['owner_name'] = df[col].apply(clean_owner_list_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a fuzzy match score of name against email\n",
    "def name_matching_with_email(email_id: str, owner_name: str):\n",
    "    if email_id == None or email_id == '' or owner_name.strip('[|]') == '':\n",
    "        return (0,0,0)\n",
    "    # print(email_id)\n",
    "    email_id = email_id.lower()\n",
    "    owner_name = owner_name.lower()\n",
    "    \n",
    "    email_str1 = re.sub('[0-9]', '',' '.join(email_id.split('@')[0].split('.')))\n",
    "    if len(email_str1)>=3 :\n",
    "        name_str1 = [val.strip(' ') for val in re.split(' |-',owner_name) if not val.strip(' ') in ['']]\n",
    "        permute_list = list(permutations(name_str1))\n",
    "        max_ratio = 0\n",
    "        max_partial = 0\n",
    "        max_token = 0\n",
    "        name_match_score = 0\n",
    "        \n",
    "        for i in range(len(name_str1)):\n",
    "    \n",
    "            if len(name_str1[i])>=3 and name_str1[i] in email_id:\n",
    "                name_match_score = name_match_score + (100/len(name_str1))\n",
    "            \n",
    "            permute_str1 = ' '.join(list(permute_list[i]))\n",
    "            permute_str2 = ''.join(list(permute_list[i]))\n",
    "            \n",
    "            score_ratio1 = fuzz.ratio(email_str1, permute_str1)\n",
    "            score_partial1 = fuzz.partial_ratio(email_str1, permute_str1)\n",
    "            score_token1 = fuzz.token_sort_ratio(email_str1, permute_str1)\n",
    "    \n",
    "            score_ratio2 = fuzz.ratio(email_str1, permute_str2)\n",
    "            score_partial2 = fuzz.partial_ratio(email_str1, permute_str2)\n",
    "            score_token2 = fuzz.token_sort_ratio(email_str1, permute_str2)\n",
    "    \n",
    "            max_ratio = max([max_ratio, score_ratio1, score_ratio2])\n",
    "            max_partial = max([max_partial, score_partial1, score_partial2])\n",
    "            max_token = max([max_token, score_token1, score_token2])\n",
    "\n",
    "    else:\n",
    "        return (0,0,0)\n",
    "        \n",
    "    return (max_ratio, max_partial, name_match_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ownername_email_match = ['ownername_email_fuzzy_match_ratio','ownername_email_fuzzy_match', 'ownername_email_substring_match']\n",
    "df[ownername_email_match] = pd.DataFrame(df.apply(lambda x: name_matching_with_email(x['email'], x['owner_name']), axis=1\n",
    "                                                     ).tolist(),index=df.index)\n",
    "\n",
    "companyname_email_match = ['companyname_email_fuzzy_match_ratio','companyname_email_fuzzy_match', 'companyname_email_substring_match']\n",
    "df[companyname_email_match] = pd.DataFrame(df.apply(lambda x: name_matching_with_email(x['email'], x['company_name']), axis=1\n",
    "                                                     ).tolist(),index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_name_email_match_flag'] = np.where(((df.companyname_email_fuzzy_match_ratio>=75)|(df.companyname_email_substring_match>=20)) |\n",
    "((df.companyname_email_fuzzy_match_ratio>=70) & (df.companyname_email_fuzzy_match>=80)), 1, 0)\n",
    "\n",
    "df['owner_name_email_match_flag'] = np.where(((df.ownername_email_fuzzy_match_ratio>=75)|(df.ownername_email_substring_match>=20)) |\n",
    "((df.ownername_email_fuzzy_match_ratio>=70) & (df.ownername_email_fuzzy_match>=80)), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4505, 417)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(project_path+'data/oot_engg_data_'+year+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person_fraud_score',\n",
       " 'person_kyc_score',\n",
       " 'sentilink_abuse_score',\n",
       " 'sentilink_first_party_synthetic_score',\n",
       " 'sentilink_third_party_synthetic_score',\n",
       " 'sentilink_id_theft_score',\n",
       " 'socure_sigma',\n",
       " 'socure_emailrisk',\n",
       " 'socure_phonerisk',\n",
       " 'socure_addressrisk',\n",
       " 'number_of_employees',\n",
       " 'business_address_zip',\n",
       " 'phone',\n",
       " 'ein_ssn',\n",
       " 'has_international_business',\n",
       " 'iovation_device_type',\n",
       " 'estimated_monthly_revenue',\n",
       " 'incoming_ach_payments',\n",
       " 'check_deposit_amount',\n",
       " 'incoming_wire_transfer',\n",
       " 'outgoing_ach_and_checks',\n",
       " 'outgoing_wire_transfers',\n",
       " 'line_type',\n",
       " 'industry_category_name',\n",
       " 'person_fraud_tags',\n",
       " 'person_kyc_tags',\n",
       " 'socure_reason_code',\n",
       " 'socure_kyc_field_validations',\n",
       " 'socure_kyc_reason_code',\n",
       " 'socure_emailrisk_reason_code',\n",
       " 'socure_phonerisk_reason_code',\n",
       " 'socure_addressrisk_reason_code',\n",
       " 'purpose_of_account',\n",
       " 'touch_point_emails',\n",
       " 'owner_list',\n",
       " 'iovation_device_timezone',\n",
       " 'iovation_device_ip',\n",
       " 'iovation_device_ip_isp',\n",
       " 'iovation_device_ip_org',\n",
       " 'iovation_device_ip_city',\n",
       " 'iovation_device_ip_region',\n",
       " 'carrier',\n",
       " 'email',\n",
       " 'email_domain',\n",
       " 'industry_name',\n",
       " 'website',\n",
       " 'business_address_city',\n",
       " 'business_address_state',\n",
       " 'industry_category_from_pitch',\n",
       " 'company_name',\n",
       " 'business_pitch',\n",
       " 'application_id',\n",
       " 'business_id',\n",
       " 'target',\n",
       " 'expensed_fraud_loss',\n",
       " 'fraud_score',\n",
       " 'deposit_score',\n",
       " 'application_start_datetime',\n",
       " 'application_complete_datetime',\n",
       " 'application_resubmitted_datetime',\n",
       " 'app_start_dateofmonth',\n",
       " 'app_start_weekofmonth',\n",
       " 'app_start_dayofweek',\n",
       " 'app_start_hourofday',\n",
       " 'app_complete_dateofmonth',\n",
       " 'app_complete_weekofmonth',\n",
       " 'app_complete_dayofweek',\n",
       " 'app_complete_hourofday',\n",
       " 'estimated_features_0k_count',\n",
       " 'estimated_features_1k_count',\n",
       " 'estimated_features_1k_plus_count',\n",
       " 'estimated_features_5k_plus_count',\n",
       " 'estimated_features_50k_plus_count',\n",
       " 'estimated_features_same_value_flag',\n",
       " 'total_incoming_vol',\n",
       " 'total_outgoing_vol',\n",
       " 'total_txns_vol',\n",
       " 'cashflow',\n",
       " 'ach_mrdc_incoming_vol',\n",
       " 'ach_mrdc_outgoing_vol',\n",
       " 'ach_mrdc_total_txns_vol',\n",
       " 'ach_mrdc_cashflow',\n",
       " 'wire_incoming_vol',\n",
       " 'wire_outgoing_vol',\n",
       " 'wire_total_txns_vol',\n",
       " 'wire_cashflow',\n",
       " 'outgoing_to_incoming_ratio',\n",
       " 'cashflow_to_total_txns_vol_ratio',\n",
       " 'wire_outgoing_to_incoming_ratio',\n",
       " 'ach_mrdc_outgoing_to_incoming_ratio',\n",
       " 'incoming_ach_to_revenue_ratio',\n",
       " 'incoming_ach_mrdc_to_revenue_ratio',\n",
       " 'ach_mrdc_total_txns_vol_to_total_txns_vol_ratio',\n",
       " 'ach_mrdc_incoming_to_total_incoming_vol_ratio',\n",
       " 'ach_mrdc_outgoing_to_total_outgoing_vol_ratio',\n",
       " 'wire_total_txns_vol_to_total_txns_vol_ratio',\n",
       " 'wire_incoming_to_total_incoming_vol_ratio',\n",
       " 'wire_outgoing_to_total_outgoing_vol_ratio',\n",
       " 'total_incoming_vol_to_employees_ratio',\n",
       " 'total_outgoing_vol_to_employees_ratio',\n",
       " 'total_txns_vol_to_employees_ratio',\n",
       " 'cashflow_to_employees_ratio',\n",
       " 'wire_incoming_vol_to_employees_ratio',\n",
       " 'wire_outgoing_vol_to_employees_ratio',\n",
       " 'wire_total_txns_vol_to_employees_ratio',\n",
       " 'wire_cashflow_to_employees_ratio',\n",
       " 'ach_mrdc_incoming_vol_to_employees_ratio',\n",
       " 'ach_mrdc_outgoing_vol_to_employees_ratio',\n",
       " 'ach_mrdc_total_txns_vol_to_employees_ratio',\n",
       " 'ach_mrdc_cashflow_to_employees_ratio',\n",
       " 'estimated_monthly_revenue_to_employees_ratio',\n",
       " 'ip_class',\n",
       " 'flesch_reading_ease',\n",
       " 'smog_index',\n",
       " 'flesch_kincaid_grade',\n",
       " 'coleman_liau_index',\n",
       " 'automated_readability_index',\n",
       " 'dale_chall_readability_score',\n",
       " 'difficult_words',\n",
       " 'linsear_write_formula',\n",
       " 'gunning_fog',\n",
       " 'text_standard',\n",
       " 'text_standard_levels',\n",
       " 'total_word_count',\n",
       " 'sentence_count',\n",
       " 'average_sentence_length',\n",
       " 'average_word_length',\n",
       " 'syllable_count',\n",
       " 'polysyllable_count',\n",
       " 'unique_words_count',\n",
       " 'type_token_ratio',\n",
       " 'lexical_density',\n",
       " 'pos_counts',\n",
       " 'textblob_polarity',\n",
       " 'textblob_subjectivity',\n",
       " 'vader_neg',\n",
       " 'vader_neu',\n",
       " 'vader_pos',\n",
       " 'vader_compound',\n",
       " 'pos_diversity',\n",
       " 'noun_to_verb_ratio',\n",
       " 'pos_ratios',\n",
       " 'pos_count_NN',\n",
       " 'pos_count_NNS',\n",
       " 'pos_count_NNP',\n",
       " 'pos_count_NNPS',\n",
       " 'pos_count_VB',\n",
       " 'pos_count_VBP',\n",
       " 'pos_count_VBG',\n",
       " 'pos_count_VBN',\n",
       " 'pos_count_VBZ',\n",
       " 'pos_count_VBD',\n",
       " 'pos_count_CC',\n",
       " 'pos_count_PRP',\n",
       " 'pos_count_JJ',\n",
       " 'pos_count_TO',\n",
       " 'pos_count_IN',\n",
       " 'pos_count_RB',\n",
       " 'pos_ratio_NN',\n",
       " 'pos_ratio_NNS',\n",
       " 'pos_ratio_NNP',\n",
       " 'pos_ratio_NNPS',\n",
       " 'pos_ratio_VB',\n",
       " 'pos_ratio_VBP',\n",
       " 'pos_ratio_VBG',\n",
       " 'pos_ratio_VBN',\n",
       " 'pos_ratio_VBZ',\n",
       " 'pos_ratio_VBD',\n",
       " 'pos_ratio_CC',\n",
       " 'pos_ratio_PRP',\n",
       " 'pos_ratio_JJ',\n",
       " 'pos_ratio_TO',\n",
       " 'pos_ratio_IN',\n",
       " 'pos_ratio_RB',\n",
       " 'socure_emailrisk_reason_code_r573',\n",
       " 'socure_reason_code_i127',\n",
       " 'socure_kyc_reason_code_r928',\n",
       " 'socure_addressrisk_reason_code_r707',\n",
       " 'socure_kyc_reason_code_r972',\n",
       " 'socure_addressrisk_code_count',\n",
       " 'socure_kyc_reason_code_r902',\n",
       " 'socure_reason_code_r204',\n",
       " 'socure_phonerisk_reason_code_r602',\n",
       " 'socure_phonerisk_reason_code_r636',\n",
       " 'socure_reason_code_r206',\n",
       " 'socure_emailrisk_reason_code_i560',\n",
       " 'socure_phonerisk_reason_code_r627',\n",
       " 'socure_addressrisk_reason_code_r704',\n",
       " 'socure_phonerisk_reason_code_i601',\n",
       " 'socure_addressrisk_reason_code_i706',\n",
       " 'socure_reason_code_r207',\n",
       " 'socure_addressrisk_reason_code_r701',\n",
       " 'socure_reason_code_r209',\n",
       " 'socure_emailrisk_reason_code_i567',\n",
       " 'socure_kyc_reason_code_i911',\n",
       " 'socure_phonerisk_reason_code_r605',\n",
       " 'socure_kyc_reason_code_r956',\n",
       " 'socure_emailrisk_reason_code_r567',\n",
       " 'socure_phonerisk_reason_code_r623',\n",
       " 'socure_addressrisk_reason_code_r713',\n",
       " 'socure_kyc_reason_code_i919',\n",
       " 'socure_phonerisk_reason_code_i634',\n",
       " 'socure_kyc_reason_code_r927',\n",
       " 'socure_phonerisk_reason_code_r646',\n",
       " 'socure_reason_code_i351',\n",
       " 'socure_phonerisk_reason_code_i632',\n",
       " 'socure_kyc_reason_code_i921',\n",
       " 'socure_phonerisk_reason_code_r640',\n",
       " 'socure_addressrisk_reason_code_i712',\n",
       " 'socure_phonerisk_reason_code_i635',\n",
       " 'socure_phonerisk_reason_code_r635',\n",
       " 'socure_reason_code_r205',\n",
       " 'socure_reason_code_i350',\n",
       " 'socure_emailrisk_reason_code_i561',\n",
       " 'socure_addressrisk_reason_code_i713',\n",
       " 'socure_phonerisk_reason_code_r659',\n",
       " 'socure_phonerisk_reason_code_r655',\n",
       " 'socure_phonerisk_reason_code_i608',\n",
       " 'socure_emailrisk_reason_code_r559',\n",
       " 'socure_phonerisk_reason_code_i631',\n",
       " 'socure_phonerisk_reason_code_i637',\n",
       " 'socure_phonerisk_reason_code_r629',\n",
       " 'socure_emailrisk_reason_code_i520',\n",
       " 'socure_kyc_reason_code_i930',\n",
       " 'socure_reason_code_r208',\n",
       " 'socure_phonerisk_reason_code_r633',\n",
       " 'socure_reason_code_count',\n",
       " 'socure_phonerisk_reason_code_r621',\n",
       " 'socure_phonerisk_reason_code_r630',\n",
       " 'socure_addressrisk_reason_code_r702',\n",
       " 'socure_reason_code_r214',\n",
       " 'socure_phonerisk_reason_code_r650',\n",
       " 'socure_reason_code_r619',\n",
       " 'socure_phonerisk_reason_code_r626',\n",
       " 'socure_kyc_reason_code_r911',\n",
       " 'socure_kyc_reason_code_r948',\n",
       " 'socure_phonerisk_reason_code_r624',\n",
       " 'socure_addressrisk_reason_code_r712',\n",
       " 'socure_reason_code_r203',\n",
       " 'socure_phonerisk_reason_code_r607',\n",
       " 'socure_phonerisk_reason_code_r614',\n",
       " 'socure_emailrisk_reason_code_i555',\n",
       " 'socure_phonerisk_reason_code_i618',\n",
       " 'socure_emailrisk_reason_code_i568',\n",
       " 'socure_phonerisk_reason_code_i616',\n",
       " 'socure_phonerisk_reason_code_r628',\n",
       " 'socure_phonerisk_reason_code_r617',\n",
       " 'socure_addressrisk_reason_code_i716',\n",
       " 'socure_emailrisk_reason_code_r569',\n",
       " 'socure_kyc_reason_code_r922',\n",
       " 'socure_kyc_reason_code_r940',\n",
       " 'socure_phonerisk_reason_code_r613',\n",
       " 'socure_phonerisk_reason_code_i620',\n",
       " 'socure_reason_code_r202',\n",
       " 'socure_kyc_reason_code_r944',\n",
       " 'socure_kyc_code_count',\n",
       " 'socure_emailrisk_reason_code_r566',\n",
       " 'socure_phonerisk_reason_code_i630',\n",
       " 'socure_kyc_reason_code_r961',\n",
       " 'socure_addressrisk_reason_code_r711',\n",
       " 'socure_phonerisk_reason_code_r616',\n",
       " 'socure_phonerisk_reason_code_r662',\n",
       " 'socure_emailrisk_reason_code_i551',\n",
       " 'socure_kyc_reason_code_i912',\n",
       " 'socure_reason_code_r217',\n",
       " 'socure_kyc_reason_code_r955',\n",
       " 'socure_emailrisk_code_count',\n",
       " 'socure_phonerisk_reason_code_r601',\n",
       " 'socure_phonerisk_reason_code_r615',\n",
       " 'socure_kyc_reason_code_r930',\n",
       " 'socure_emailrisk_reason_code_r520',\n",
       " 'socure_phonerisk_reason_code_r638',\n",
       " 'socure_kyc_reason_code_r919',\n",
       " 'socure_phonerisk_reason_code_r661',\n",
       " 'socure_emailrisk_reason_code_i564',\n",
       " 'socure_phonerisk_reason_code_i610',\n",
       " 'socure_kyc_reason_code_r907',\n",
       " 'socure_kyc_reason_code_r957',\n",
       " 'socure_phonerisk_reason_code_r639',\n",
       " 'socure_emailrisk_reason_code_r562',\n",
       " 'socure_addressrisk_reason_code_i705',\n",
       " 'socure_reason_code_i201',\n",
       " 'socure_kyc_reason_code_r947',\n",
       " 'socure_kyc_reason_code_i909',\n",
       " 'socure_addressrisk_reason_code_r720',\n",
       " 'socure_phonerisk_reason_code_r642',\n",
       " 'socure_kyc_reason_code_r978',\n",
       " 'socure_phonerisk_reason_code_r611',\n",
       " 'socure_addressrisk_reason_code_r714',\n",
       " 'socure_phonerisk_reason_code_r657',\n",
       " 'socure_addressrisk_reason_code_r703',\n",
       " 'socure_reason_code_r215',\n",
       " 'socure_addressrisk_reason_code_i711',\n",
       " 'socure_phonerisk_reason_code_r648',\n",
       " 'socure_phonerisk_reason_code_i626',\n",
       " 'socure_phonerisk_reason_code_i609',\n",
       " 'socure_phonerisk_reason_code_r653',\n",
       " 'socure_addressrisk_reason_code_i714',\n",
       " 'socure_phonerisk_reason_code_r622',\n",
       " 'socure_emailrisk_reason_code_i553',\n",
       " 'socure_kyc_reason_code_r973',\n",
       " 'socure_addressrisk_reason_code_i715',\n",
       " 'socure_phonerisk_reason_code_r625',\n",
       " 'socure_emailrisk_reason_code_r560',\n",
       " 'socure_reason_code_r218',\n",
       " 'socure_addressrisk_reason_code_i721',\n",
       " 'socure_kyc_reason_code_r932',\n",
       " 'socure_reason_code_r210',\n",
       " 'socure_kyc_reason_code_i917',\n",
       " 'socure_kyc_reason_code_r941',\n",
       " 'socure_phonerisk_reason_code_r656',\n",
       " 'socure_emailrisk_reason_code_r568',\n",
       " 'socure_phonerisk_reason_code_r604',\n",
       " 'socure_phonerisk_reason_code_r618',\n",
       " 'socure_phonerisk_reason_code_r637',\n",
       " 'socure_kyc_reason_code_r976',\n",
       " 'socure_reason_code_i121',\n",
       " 'socure_kyc_reason_code_r977',\n",
       " 'socure_addressrisk_reason_code_i722',\n",
       " 'socure_addressrisk_reason_code_i720',\n",
       " 'socure_kyc_reason_code_r909',\n",
       " 'socure_phonerisk_reason_code_r632',\n",
       " 'socure_addressrisk_reason_code_r705',\n",
       " 'socure_phonerisk_reason_code_r641',\n",
       " 'socure_emailrisk_reason_code_r561',\n",
       " 'socure_kyc_reason_code_r979',\n",
       " 'socure_phonerisk_reason_code_i636',\n",
       " 'socure_emailrisk_reason_code_i570',\n",
       " 'socure_phonerisk_reason_code_i602',\n",
       " 'socure_all_codes_count',\n",
       " 'socure_phonerisk_reason_code_r620',\n",
       " 'socure_phonerisk_code_count',\n",
       " 'socure_emailrisk_reason_code_i556',\n",
       " 'socure_kyc_reason_code_i910',\n",
       " 'socure_emailrisk_reason_code_r557',\n",
       " 'socure_kyc_reason_code_r920',\n",
       " 'socure_emailrisk_reason_code_r571',\n",
       " 'socure_addressrisk_reason_code_i707',\n",
       " 'socure_kyc_reason_code_r924',\n",
       " 'socure_kyc_reason_code_r901',\n",
       " 'socure_kyc_reason_code_r946',\n",
       " 'socure_emailrisk_reason_code_i552',\n",
       " 'socure_emailrisk_reason_code_r572',\n",
       " 'socure_kyc_reason_code_r964',\n",
       " 'socure_emailrisk_reason_code_r574',\n",
       " 'socure_addressrisk_reason_code_i708',\n",
       " 'socure_kyc_reason_code_i907',\n",
       " 'socure_phonerisk_reason_code_i638',\n",
       " 'socure_kyc_reason_code_r903',\n",
       " 'socure_emailrisk_reason_code_r551',\n",
       " 'socure_addressrisk_reason_code_i704',\n",
       " 'socure_phonerisk_reason_code_r606',\n",
       " 'socure_phonerisk_reason_code_r647',\n",
       " 'socure_kyc_reason_code_r939',\n",
       " 'socure_addressrisk_reason_code_r708',\n",
       " 'socure_phonerisk_reason_code_i611',\n",
       " 'socure_emailrisk_reason_code_r565',\n",
       " 'socure_reason_code_r610',\n",
       " 'socure_phonerisk_reason_code_r660',\n",
       " 'socure_kyc_reason_code_r980',\n",
       " 'socure_phonerisk_reason_code_r631',\n",
       " 'socure_kyc_reason_code_r963',\n",
       " 'socure_emailrisk_reason_code_i566',\n",
       " 'socure_reason_code_r219',\n",
       " 'socure_addressrisk_reason_code_r721',\n",
       " 'socure_emailrisk_reason_code_i550',\n",
       " 'socure_phonerisk_reason_code_r608',\n",
       " 'socure_emailrisk_reason_code_i562',\n",
       " 'socure_phonerisk_reason_code_i639',\n",
       " 'socure_phonerisk_reason_code_v120',\n",
       " 'socure_phonerisk_reason_code_r654',\n",
       " 'socure_kyc_reason_code_i920',\n",
       " 'socure_emailrisk_reason_code_r558',\n",
       " 'socure_phonerisk_reason_code_i633',\n",
       " 'socure_emailrisk_reason_code_i565',\n",
       " 'socure_emailrisk_reason_code_i569',\n",
       " 'socure_reason_code_r211',\n",
       " 'socure_phonerisk_reason_code_r644',\n",
       " 'socure_phonerisk_reason_code_i625',\n",
       " 'socure_kyc_reason_code_r933',\n",
       " 'socure_reason_code_r212',\n",
       " 'socure_reason_code_r216',\n",
       " 'socure_phonerisk_reason_code_r643',\n",
       " 'socure_kyc_reason_code_r934',\n",
       " 'socure_phonerisk_reason_code_i614',\n",
       " 'socure_phonerisk_reason_code_r603',\n",
       " 'socure_reason_code_r351',\n",
       " 'socure_kyc_reason_code_r916',\n",
       " 'socure_addressrisk_reason_code_r709',\n",
       " 'socure_emailrisk_reason_code_r563',\n",
       " 'socure_phonerisk_reason_code_r658',\n",
       " 'socure_kyc_surname_score',\n",
       " 'socure_kyc_firstname_score',\n",
       " 'socure_kyc_dob_score',\n",
       " 'socure_kyc_mobilenumber_score',\n",
       " 'socure_kyc_ssn_score',\n",
       " 'socure_kyc_state_score',\n",
       " 'socure_kyc_city_score',\n",
       " 'socure_kyc_streetaddress_score',\n",
       " 'socure_kyc_zip_score',\n",
       " 'purpose_payroll',\n",
       " 'purpose_accounting',\n",
       " 'purpose_operating',\n",
       " 'purpose_travel_expenses',\n",
       " 'purpose_business_expenses',\n",
       " 'purpose_of_account_count',\n",
       " 'person_fraud_tags_flag',\n",
       " 'person_kyc_tags_flag',\n",
       " 'owner_name',\n",
       " 'ownername_email_fuzzy_match_ratio',\n",
       " 'ownername_email_fuzzy_match',\n",
       " 'ownername_email_substring_match',\n",
       " 'companyname_email_fuzzy_match_ratio',\n",
       " 'companyname_email_fuzzy_match',\n",
       " 'companyname_email_substring_match',\n",
       " 'company_name_email_match_flag',\n",
       " 'owner_name_email_match_flag']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4505, 417)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 6, 18, 9, 18, 9, 888)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fa8e7a0e7c7188de72acea4ae1bc222d1770499c4c3d36ce32843ef46b20053"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
