{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path variables\n",
    "import sys\n",
    "import json\n",
    "project_path = '/Users/naresh/Downloads/ds_models/onboarding_fraud_model_v2/'\n",
    "sys.path.insert(0, project_path+'config')\n",
    "\n",
    "# core libraries\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from config import SQLQuery\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = SQLQuery('snowflake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing the sardine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_sardine = q(\"\"\"\n",
    "\n",
    "# with owners_data_tmp as (\n",
    "# select b.application_id, a.*, rank() over(partition by application_id order by a.created_at) as rk\n",
    "# from \"FIVETRAN_DB\".\"PROD_NOVO_ONBOARDING_PUBLIC\".\"OWNER_RISK_DETAILS\" a\n",
    "# inner join FIVETRAN_DB.PROD_NOVO_ONBOARDING_PUBLIC.OWNERS b on a.owners_id=b.id\n",
    "# )\n",
    "\n",
    "# select b.*\n",
    "# from prod_db.data.businesses a\n",
    "# inner join (select * from owners_data_tmp where rk=1) b on a.application_id=b.application_id\n",
    "# where 1=1 \n",
    "# and a.account_create_date between '2023-01-01' and '2023-12-31'\n",
    "# and a.business_type ilike '%sole%'\n",
    "\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sardine = pd.read_pickle(project_path+'data/df_sardine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23333, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sardine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['checkpointdata', 'checkpoints', 'customer', 'device', 'level', 'rules', 'sessionkey', 'status'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][0].lower()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': {'validity': 'unknown'},\n",
       " 'level': 'low',\n",
       " 'score': 4,\n",
       " 'signals': [{'key': 'addressrisklevel', 'value': 'low'},\n",
       "  {'key': 'emaildomainlevel', 'value': 'low'},\n",
       "  {'key': 'emaillevel', 'value': 'low'},\n",
       "  {'key': 'phonelevel', 'value': 'low'},\n",
       "  {'key': 'manualreview', 'value': 'false'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][6].lower())['customer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attributes': {'browser': ['mobile safari'],\n",
       "  'model': ['iphone'],\n",
       "  'os': ['ios']},\n",
       " 'behaviorbiometrics': {'hesitationpercentile': {'ltm': 0, 'nonltm': 0},\n",
       "  'numcontextswitchevents': 0,\n",
       "  'numdistractionevents': 0,\n",
       "  'pagefieldltm': {'absolute': {'hesitationpercentage': 0,\n",
       "    'isltm': False,\n",
       "    'numautofillevents': 0,\n",
       "    'numclipboardevents': 0,\n",
       "    'numcopypasteevents': 0,\n",
       "    'numexpertkeyevents': 0,\n",
       "    'timespendinms': 0,\n",
       "    'timespendinmsevents': None},\n",
       "   'average': {'hesitationpercentage': 0,\n",
       "    'isltm': False,\n",
       "    'numautofillevents': 0,\n",
       "    'numclipboardevents': 0,\n",
       "    'numcopypasteevents': 0,\n",
       "    'numexpertkeyevents': 0,\n",
       "    'timespendinms': 0,\n",
       "    'timespendinmsevents': None},\n",
       "   'percent': {'hesitationpercentage': 0,\n",
       "    'isltm': False,\n",
       "    'numautofillevents': 0,\n",
       "    'numclipboardevents': 0,\n",
       "    'numcopypasteevents': 0,\n",
       "    'numexpertkeyevents': 0,\n",
       "    'timespendinms': 0,\n",
       "    'timespendinmsevents': None}},\n",
       "  'pagefieldnonltm': {'absolute': {'hesitationpercentage': 0,\n",
       "    'isltm': False,\n",
       "    'numautofillevents': 0,\n",
       "    'numclipboardevents': 0,\n",
       "    'numcopypasteevents': 0,\n",
       "    'numexpertkeyevents': 0,\n",
       "    'timespendinms': 0,\n",
       "    'timespendinmsevents': None},\n",
       "   'average': {'hesitationpercentage': 0,\n",
       "    'isltm': False,\n",
       "    'numautofillevents': 0,\n",
       "    'numclipboardevents': 0,\n",
       "    'numcopypasteevents': 0,\n",
       "    'numexpertkeyevents': 0,\n",
       "    'timespendinms': 0,\n",
       "    'timespendinmsevents': None},\n",
       "   'percent': {'hesitationpercentage': 0,\n",
       "    'isltm': False,\n",
       "    'numautofillevents': 0,\n",
       "    'numclipboardevents': 0,\n",
       "    'numcopypasteevents': 0,\n",
       "    'numexpertkeyevents': 0,\n",
       "    'timespendinms': 0,\n",
       "    'timespendinmsevents': None}},\n",
       "  'typingspeed': {}},\n",
       " 'checkpoints': {'device': {}},\n",
       " 'confidencescore': 0.34941536,\n",
       " 'devicereputation': 'medium_risk',\n",
       " 'fingerprint': '621f0661-009e-4cad-afbc-953134141a06',\n",
       " 'fingerprintconfidencescore': 35,\n",
       " 'id': '5808a897-f3c9-45ee-ae8f-0dd62fcf205b',\n",
       " 'ipaddresses': {'v4': '75.227.98.213'},\n",
       " 'iplocation': {'city': 'new york city',\n",
       "  'country': 'us',\n",
       "  'latitude': '40.71',\n",
       "  'longitude': '-74.01',\n",
       "  'region': 'new york'},\n",
       " 'level': 'low',\n",
       " 'sessionkey': '4364e73f5c4f9c098f2dff29d46b10f603cbdf178e2759200099de44c30a5f9e',\n",
       " 'signals': [{'key': 'trueos', 'value': 'mac/ios'},\n",
       "  {'key': 'deviceagehours', 'value': '0'},\n",
       "  {'key': 'trueip', 'value': '75.227.98.213'},\n",
       "  {'key': 'vpn', 'value': 'low'},\n",
       "  {'key': 'proxy', 'value': 'low'},\n",
       "  {'key': 'remotesoftware', 'value': 'false'},\n",
       "  {'key': 'remotesoftwarelevel', 'value': 'low'},\n",
       "  {'key': 'osanomaly', 'value': 'low'},\n",
       "  {'key': 'emulator', 'value': 'false'},\n",
       "  {'key': 'tamperedapp', 'value': ''},\n",
       "  {'key': 'iptype', 'value': 'fixed line isp / mobile isp'},\n",
       "  {'key': 'sessionipcount', 'value': '1'},\n",
       "  {'key': 'sessionipcountrycount', 'value': '1'},\n",
       "  {'key': 'remotesessionlevel', 'value': ''},\n",
       "  {'key': 'accountdeviceid', 'value': '865b6a96-eaea-4883-97be-a35f973adabf'},\n",
       "  {'key': 'behaviorbiometriclevel', 'value': 'low'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][0].lower())['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attributes', 'behaviorbiometrics', 'checkpoints', 'confidencescore', 'devicereputation', 'fingerprint', 'fingerprintconfidencescore', 'id', 'ipaddresses', 'iplocation', 'level', 'sessionkey', 'signals'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][0].lower())['device'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fields', 'flowtimesinms', 'hesitationpercentile', 'numcontextswitchevents', 'numdistractionevents', 'pagefieldltm', 'pagefieldnonltm', 'totaltimespentinms', 'typingspeed'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][1].lower())['device']['behaviorbiometrics'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'browser': ['chrome'], 'model': [''], 'os': ['windows']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][1].lower())['device']['attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][1].lower())['device']['confidencescore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medium_risk'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][10].lower())['device']['devicereputation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': 'trueos', 'value': 'mac/ios'},\n",
       " {'key': 'deviceagehours', 'value': '0'},\n",
       " {'key': 'trueip', 'value': '166.199.3.145'},\n",
       " {'key': 'vpn', 'value': 'low'},\n",
       " {'key': 'proxy', 'value': 'low'},\n",
       " {'key': 'remotesoftware', 'value': 'false'},\n",
       " {'key': 'remotesoftwarelevel', 'value': 'low'},\n",
       " {'key': 'osanomaly', 'value': 'low'},\n",
       " {'key': 'emulator', 'value': 'false'},\n",
       " {'key': 'tamperedapp', 'value': ''},\n",
       " {'key': 'iptype', 'value': 'mobile isp'},\n",
       " {'key': 'sessionipcount', 'value': '2'},\n",
       " {'key': 'sessionipcountrycount', 'value': '1'},\n",
       " {'key': 'remotesessionlevel', 'value': ''},\n",
       " {'key': 'accountdeviceid', 'value': '11331843-f5ea-411b-969a-5981e427b85f'},\n",
       " {'key': 'behaviorbiometriclevel', 'value': 'low'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df_sardine['meta'][10].lower())['device']['signals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Extraction Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_mapping = {\n",
    "    'otp':'otp', 'phone otp':'phone_otp', 'business_type':'business_type',\n",
    "    'day':'day', 'month':'month', 'year':'year', \n",
    "    'phone':'phone', '(201) 555-5555':'phone',\n",
    "    'ssn':'ssn', 'enter your ssn':'ssn', 'ein':'ein', 'ein_disclosure':'ein_disclosure', \n",
    "    'last_name':'last_name', 'enter your last name':'last_name',\n",
    "    'first_name':'first_name', 'enter your first name':'first_name',\n",
    "    'middle_name':'middle_name', 'enter your middle name':'middle_name',\n",
    "    \n",
    "    'purpose_of_account':'purpose_of_account', 'purpose_option':'purpose_of_account',\n",
    "    \n",
    "    'outgoing_wire_transfers':'outgoing_wire_transfers', 'business_questions#outgoing_wire_transfers':'outgoing_wire_transfers',\n",
    "    'estimated_monthly_revenue':'estimated_monthly_revenue', 'business_questions#estimated_monthly_revenue':'estimated_monthly_revenue',\n",
    "    'incoming_ach_payments':'incoming_ach_payments', 'business_questions#incoming_ach_payments':'incoming_ach_payments',\n",
    "    'check_deposit_amount':'check_deposit_amount', 'business_questions#check_deposit_amount':'check_deposit_amount',\n",
    "    'outgoing_ach_and_checks':'outgoing_ach_and_checks', 'business_questions#outgoing_ach_and_checks':'outgoing_ach_and_checks',\n",
    "    'incoming_wire_transfer':'incoming_wire_transfer', 'business_questions#incoming_wire_transfer':'incoming_wire_transfer',\n",
    "    \n",
    "    'number_of_employees':'number_of_employees', 'enter estimated number of employees':'number_of_employees',\n",
    "    'website':'website', 'yourbusiness.com (optional)':'website',\n",
    "    # 'referral_code':'referral_code', \n",
    "    'company_name':'company_name', 'business#company_name':'company_name',\n",
    "    'business_pitch':'business_pitch',\n",
    "    'eg. we provide a lunch catering service for companies around 100 employees':'business_pitch',\n",
    "    \"par exemple.  nous proposons un service de restauration pour le déjeuner aux entreprises d'environ 100 salariés\":'business_pitch',\n",
    "    \"eg. we provide a lunch catering service for companies around 100 employees, so they don’t need to organize their own kitchen services in house. we operate exclusively in new york city but have plans to eventually setup operations in boston as well. our main source of revenue comes from selling monthly subscriptions for our luch catering service, with choice of an entry level, or premium package.\":'business_pitch' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert list of dicts to dicts with 'name' key values\n",
    "def name_list_of_dicts_by_key(list_of_dicts, key_name):\n",
    "    # Initialize an empty dictionary to hold the named result\n",
    "    named_dict = {}\n",
    "    \n",
    "    # Iterate over each dictionary in the list\n",
    "    for d in list_of_dicts:\n",
    "        # Extract the value for the specified key to use as the new key\n",
    "        if key_name in d:\n",
    "            new_key = d[key_name]\n",
    "            named_dict[new_key] = d\n",
    "        else:\n",
    "            print(f\"Warning: Key '{key_name}' not found in dictionary {d}\")\n",
    "    \n",
    "    return named_dict\n",
    "\n",
    "# Function to replace 'name' key values\n",
    "def replace_name_values(data, keys_mapping_dict):\n",
    "    for item in data:\n",
    "        try:\n",
    "            item['name'] = keys_mapping_dict[item['name']]\n",
    "        except:\n",
    "            continue\n",
    "    return data\n",
    "    \n",
    "# Function to handle duplicate keys\n",
    "def append_duplicate_keys(dicts, key_field):\n",
    "    result = defaultdict(list)\n",
    "    for d in dicts:\n",
    "        key = d[key_field]\n",
    "        result[key].append(d)\n",
    "    return result\n",
    "\n",
    "# Function to append values of the same keys into a list\n",
    "def append_values_of_same_keys(dict_of_lists, key_name):\n",
    "    combined_dict = defaultdict(list)\n",
    "    for item in dict_of_lists[key_name]:\n",
    "        for key, value in item.items():\n",
    "            combined_dict[key].append(value)\n",
    "    return dict(combined_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Columns to Extract\n",
    "device_biometr_all_variants_keys_list = list(keys_mapping.keys())\n",
    "\n",
    "device_biometr_keys = ['business_type', 'first_name', 'middle_name', 'last_name', 'incoming_wire_transfer', 'check_deposit_amount',\n",
    "                        'incoming_ach_payments', 'estimated_monthly_revenue', 'outgoing_wire_transfers', 'outgoing_ach_and_checks',\n",
    "                        'purpose_of_account', 'otp', 'phone_otp', 'ssn', 'business_pitch', 'number_of_employees','website',\n",
    "                        'day','month','year','referral_code','company_name']\n",
    "device_biometr_fields = ['numautofillevents','numclipboardevents','numcopypasteevents','numexpertkeyevents','timespendinms',\n",
    "                         'timespendinmsevents']\n",
    "device_typing_fields = ['downspeed','firstkeydownspeed','firstkeyspeed','firstkeyupspeed','mediandowntime','medianuptime',\n",
    "                        'secondkeydownspeed','secondkeyspeed','secondkeyupspeed','typingaccuracy','typingspeed','upspeed']\n",
    "device_customer_fields = ['address_validity','level','score','addressrisklevel','emaildomainlevel','emaillevel','phonelevel']\n",
    "device_other_fields = ['trueos','deviceagehours','trueip','vpn','proxy','remotesoftware','remotesoftwarelevel','osanomaly','emulator',\n",
    "                       'tamperedapp','iptype','sessionipcount','sessionipcountrycount','remotesessionlevel','accountdeviceid',\n",
    "                       'behaviorbiometriclevel']\n",
    "device_other_attribute_columns = ['sdn_attribute_browser','sdn_attribute_model','sdn_attribute_os','sdn_device_confidencescore',\n",
    "                                  'sdn_device_devicereputation','sdn_device_fingerprintconfidencescore']\n",
    "\n",
    "device_biometr_columns = [f\"sdn_biometr_{key}_{field}\" for key in device_biometr_keys for field in device_biometr_fields]\n",
    "device_typing_columns = [f\"sdn_typing_{field}\" for field in device_typing_fields]\n",
    "device_customer_columns = [f\"sdn_customer_{field}\" for field in device_customer_fields]\n",
    "device_other_columns = [f\"sdn_other_{field}\" for field in device_other_fields]\n",
    "device_other_attribute_columns = device_other_attribute_columns\n",
    "\n",
    "# Initialize DataFrames\n",
    "device_biometr_df = pd.DataFrame(columns=device_biometr_columns)\n",
    "device_typing_df = pd.DataFrame(columns=device_typing_columns)\n",
    "device_customer_df = pd.DataFrame(columns=device_customer_columns)\n",
    "device_other_df = pd.DataFrame(columns=device_customer_columns)\n",
    "device_other_attribute_df = pd.DataFrame(columns=device_other_attribute_columns)\n",
    "\n",
    "device_biometr_except_list = []\n",
    "device_typing_except_list = []\n",
    "device_customer_except_list = []\n",
    "device_other_except_list = []\n",
    "device_other_attribute_except_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_device_biometr_signals(row):\n",
    "    try:\n",
    "        tmp_dict = {}\n",
    "        named_dict = {}\n",
    "        # Extracting Device Relevant data\n",
    "        device_data = json.loads(row['meta'].lower()).get('device', {}).get('behaviorbiometrics', {}).get('fields', [])\n",
    "        device_data = replace_name_values(device_data, keys_mapping)\n",
    "        named_dict_dup_keys = append_duplicate_keys(device_data, 'name')\n",
    "        for key in named_dict_dup_keys.keys():\n",
    "            if key in device_biometr_all_variants_keys_list:\n",
    "                key1 = keys_mapping[key]\n",
    "                named_dict[key1] = append_values_of_same_keys(named_dict_dup_keys, key1)\n",
    "                tmp_dict[f\"sdn_biometr_{key1}_numautofillevents\"] = str(named_dict.get(key1, {}).get('numautofillevents', None))\n",
    "                tmp_dict[f\"sdn_biometr_{key1}_numclipboardevents\"] = str(named_dict.get(key1, {}).get('numclipboardevents', None))\n",
    "                tmp_dict[f\"sdn_biometr_{key1}_numcopypasteevents\"] = str(named_dict.get(key1, {}).get('numcopypasteevents', None))\n",
    "                tmp_dict[f\"sdn_biometr_{key1}_numexpertkeyevents\"] = str(named_dict.get(key1, {}).get('numexpertkeyevents', None))\n",
    "                tmp_dict[f\"sdn_biometr_{key1}_timespendinms\"] = str(named_dict.get(key1, {}).get('timespendinms', None))\n",
    "                tmp_dict[f\"sdn_biometr_{key1}_timespendinmsevents\"] = str(named_dict.get(key1, {}).get('timespendinmsevents', None))\n",
    "\n",
    "        return tmp_dict\n",
    "    except:\n",
    "        device_except_list.append(row.name)\n",
    "        return pd.Series([pd.np.nan]*len(device_biometr_columns), index=device_biometr_columns)\n",
    "\n",
    "def extract_device_typing_signals(row):\n",
    "    try:\n",
    "        tmp_dict = {}\n",
    "        # Extracting Typing Speed data\n",
    "        typing_data = json.loads(row['meta'].lower()).get('device',{}).get('behaviorbiometrics',{}).get('typingspeed', [])\n",
    "        tmp_dict['sdn_typing_downspeed'] = typing_data.get('downspeed', None)\n",
    "        tmp_dict['sdn_typing_firstkeydownspeed'] = typing_data.get('firstkeydownspeed', None)\n",
    "        tmp_dict['sdn_typing_firstkeyspeed'] = typing_data.get('firstkeyspeed', None)\n",
    "        tmp_dict['sdn_typing_firstkeyupspeed'] = typing_data.get('firstkeyupspeed', None)\n",
    "        tmp_dict['sdn_typing_mediandowntime'] = typing_data.get('mediandowntime', None)\n",
    "        tmp_dict['sdn_typing_medianuptime'] = typing_data.get('medianuptime', None)\n",
    "        tmp_dict['sdn_typing_secondkeydownspeed'] = typing_data.get('secondkeydownspeed', None)\n",
    "        tmp_dict['sdn_typing__secondkeyspeed'] = typing_data.get('secondkeyspeed', None)\n",
    "        tmp_dict['sdn_typing_secondkeyupspeed'] = typing_data.get('secondkeyupspeed', None)\n",
    "        tmp_dict['sdn_typing_typingaccuracy'] = typing_data.get('typingaccuracy', None)\n",
    "        tmp_dict['sdn_typing_typingspeed'] = typing_data.get('typingspeed', None)\n",
    "        tmp_dict['sdn_typing_upspeed'] = typing_data.get('upspeed', None)\n",
    "        return tmp_dict\n",
    "    except:\n",
    "        device_typing_except_list.append(row.name)\n",
    "        return pd.Series([pd.np.nan]*len(device_typing_columns), index=device_typing_columns)\n",
    "\n",
    "\n",
    "def extract_device_customer_signals(row):\n",
    "    try:\n",
    "        signals_dict = {}\n",
    "        customer_data = json.loads(row['meta'].lower()).get('customer', {})\n",
    "        signals_dict['sdn_customer_address_validity'] = customer_data.get('address', {}).get('validity', None)\n",
    "        signals_dict['sdn_customer_level'] = customer_data.get('level', None)\n",
    "        signals_dict['sdn_customer_score'] = customer_data.get('score', None)\n",
    "\n",
    "        named_dict2 = name_list_of_dicts_by_key(customer_data.get('signals', []), 'key')\n",
    "        signals_dict['sdn_customer_addressrisklevel'] = named_dict2.get('addressrisklevel', {}).get('value', None)\n",
    "        signals_dict['sdn_customer_emaildomainlevel'] = named_dict2.get('emaildomainlevel', {}).get('value', None)\n",
    "        signals_dict['sdn_customer_emaillevel'] = named_dict2.get('emaillevel', {}).get('value', None)\n",
    "        signals_dict['sdn_customer_phonelevel'] = named_dict2.get('phonelevel', {}).get('value', None)\n",
    "        return signals_dict\n",
    "    except:\n",
    "        customer_except_list.append(row.name)\n",
    "        return pd.Series([pd.np.nan]*len(device_customer_columns), index=device_customer_columns)\n",
    "\n",
    "\n",
    "def extract_device_other_signals(row):\n",
    "    try:\n",
    "        tmp_dict = {}\n",
    "        # Extracting data\n",
    "        device_data = json.loads(row['meta'].lower()).get('device', {}).get('signals', [])\n",
    "        named_dict = name_list_of_dicts_by_key(device_data, 'key')\n",
    "\n",
    "        tmp_dict['sdn_other_trueos'] = named_dict.get('trueos', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_deviceagehours'] = named_dict.get('deviceagehours', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_trueip'] = named_dict.get('trueip', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_vpn'] = named_dict.get('vpn', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_proxy'] = named_dict.get('proxy', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_remotesoftware'] = named_dict.get('remotesoftware', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_remotesoftwarelevel'] = named_dict.get('remotesoftwarelevel', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_osanomaly'] = named_dict.get('osanomaly', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_emulator'] = named_dict.get('emulator', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_tamperedapp'] = named_dict.get('tamperedapp', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_iptype'] = named_dict.get('iptype', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_sessionipcount'] = named_dict.get('sessionipcount', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_sessionipcountrycount'] = named_dict.get('sessionipcountrycount', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_remotesessionlevel'] = named_dict.get('remotesessionlevel', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_accountdeviceid'] = named_dict.get('accountdeviceid', {}).get('value', None)\n",
    "        tmp_dict['sdn_other_behaviorbiometriclevel'] = named_dict.get('behaviorbiometriclevel', {}).get('value', None)\n",
    "        return tmp_dict\n",
    "    except:\n",
    "        device_other_except_list.append(row.name)\n",
    "        return pd.Series([pd.np.nan]*len(device_other_columns), index=device_other_columns)\n",
    "\n",
    "\n",
    "def extract_device_other_attribute_signals(row):\n",
    "    try:\n",
    "        tmp_dict = {}\n",
    "        device_data_dict = json.loads(row['meta'].lower()).get('device', {}).get('attributes', [])\n",
    "        \n",
    "        tmp_dict['sdn_attribute_browser'] = device_data_dict.get('browser', None)\n",
    "        tmp_dict['sdn_attribute_model'] = device_data_dict.get('model', None)\n",
    "        tmp_dict['sdn_attribute_os'] = device_data_dict.get('os', None)\n",
    "        tmp_dict['sdn_device_confidencescore'] = json.loads(row['meta'].lower()).get('device', {}).get('confidencescore', None)\n",
    "        tmp_dict['sdn_device_devicereputation'] = json.loads(row['meta'].lower()).get('device', {}).get('devicereputation', None)\n",
    "        tmp_dict['sdn_device_fingerprintconfidencescore'] = json.loads(row['meta'].lower()).get('device', {}\n",
    "                                                                                               ).get('fingerprintconfidencescore', None)\n",
    "        \n",
    "        return tmp_dict\n",
    "    except:\n",
    "        device_other_attribute_except_list.append(row.name)\n",
    "        return pd.Series([pd.np.nan]*len(device_other_attribute_columns), index=device_other_attribute_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sar_tmp = df_sardine[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the functions to the DataFrame\n",
    "device_biometr_df = df_sardine.apply(extract_device_biometr_signals, axis=1, result_type='expand')\n",
    "device_typing_df = df_sardine.apply(extract_device_typing_signals, axis=1, result_type='expand')\n",
    "device_customer_df = df_sardine.apply(extract_device_customer_signals, axis=1, result_type='expand')\n",
    "device_other_df = df_sardine.apply(extract_device_other_signals, axis=1, result_type='expand')\n",
    "device_other_attribute_df = df_sardine.apply(extract_device_other_attribute_signals, axis=1, result_type='expand')\n",
    "\n",
    "combined_df = pd.concat([df_sardine,device_biometr_df,device_typing_df,device_customer_df,device_other_df,device_other_attribute_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23333, 138), (23333, 13), (23333, 7), (23333, 16))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_biometr_df.shape, device_typing_df.shape, device_customer_df.shape, device_other_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_list_of_dicts_by_key(json.loads(df_sardine['meta'][1].lower())['device']['behaviorbiometrics']['fields'], 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_biometr_df[device_biometr_df.sdn_biometr_business_pitch_numexpertkeyevents.isnull()]\n",
    "# # device_other_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_biometr_df[device_biometr_df.columns[device_biometr_df.columns.str.startswith('sdn_biometr_business_pitch')==True].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_data = json.loads(df_sardine['meta'][10].lower()).get('device', {}).get('signals', [])\n",
    "# named_dict = name_list_of_dicts_by_key(device_data, 'key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_pickle(project_path+'data/sardine_data_extracted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fa8e7a0e7c7188de72acea4ae1bc222d1770499c4c3d36ce32843ef46b20053"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
